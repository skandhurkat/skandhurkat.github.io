<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine-learning on Skand Hurkat</title>
    <link>https://skandhurkat.com/tags/machine-learning/</link>
    <description>Recent content in machine-learning on Skand Hurkat</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Nov 2012 15:52:23 -0400</lastBuildDate>
    
	<atom:link href="https://skandhurkat.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>EmoDetect</title>
      <link>https://skandhurkat.com/project/emodetect/</link>
      <pubDate>Fri, 16 Nov 2012 15:52:23 -0400</pubDate>
      
      <guid>https://skandhurkat.com/project/emodetect/</guid>
      <description>We developed EmoDetect, an open source system for identifying human emotion from images. This system has an accuracy of around 63% in identifying the correct emotion from amongst seven candidates. Our experiments showed that humans did slightly better, with an accuracy of 74%.
The project was aimed as a comparative study of different feature extractors and learning algorithm combinations for the task of identifying emotion from static images. Our study revealed that Gabor features with a linear, soft margin SVM performed best.</description>
    </item>
    
    <item>
      <title>CarDetect</title>
      <link>https://skandhurkat.com/project/cardetect/</link>
      <pubDate>Sat, 16 Apr 2011 16:37:36 -0400</pubDate>
      
      <guid>https://skandhurkat.com/project/cardetect/</guid>
      <description>CarDetect is a system to identify car numberplates (registration plates) and car make and model. This system was supposed to help law enforcement officials identify fake numberplates and stolen cars. I worked on this project for over a year and achieved over 98% accuracy in recognizing numberplate regions, and over 90% accuracy in recognizing car models.
The project was implemented in OpenCV using C/C++. The code for the project can be found on my GitHub repository.</description>
    </item>
    
    <item>
      <title>Text-independent speaker verification</title>
      <link>https://skandhurkat.com/project/text-independent-speaker-verification/</link>
      <pubDate>Fri, 16 Apr 2010 17:09:15 -0400</pubDate>
      
      <guid>https://skandhurkat.com/project/text-independent-speaker-verification/</guid>
      <description>We developed a system to identify users independent of their spoken words. The system used Mel-frequency cepstral coefficients (MFCCs) to obtain a characteristic pattern of the user&amp;rsquo;s voice which was then analysed by a three layer multi-layer perceptron (MLP) neural network. We obtained accuracies of over 90% using this approach.
The entire project was implemented in MATLAB.</description>
    </item>
    
  </channel>
</rss>